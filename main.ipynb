{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXszINDMVmcQ"
      },
      "source": [
        "## **0. Подготовка окружения**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "j6XqhFlelO5n"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6_x3uBA7USkW"
      },
      "outputs": [],
      "source": [
        "# Путь к папке с данными\n",
        "DATASET_PATH = \"./data\"  # внутри: папки 1,2,...,8\n",
        "\n",
        "# !pip install mediapipe opencv-python scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "oeWd1TEelfEM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1766769714.254025 11614655 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M1 Pro\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import pickle\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "# from google.colab.patches import cv2_imshow\n",
        "import random\n",
        "\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(\n",
        "    static_image_mode=False,\n",
        "    model_complexity=1,\n",
        "    enable_segmentation=False,\n",
        "    min_detection_confidence=0.5,\n",
        "    min_tracking_confidence=0.5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQsPl9eZWGD7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def _safe_angle(a, b, c):\n",
        "    ba = a - b\n",
        "    bc = c - b\n",
        "    denom = (np.linalg.norm(ba) * np.linalg.norm(bc)) + 1e-6\n",
        "    cosv = float(np.dot(ba, bc) / denom)\n",
        "    cosv = float(np.clip(cosv, -1.0, 1.0))\n",
        "    return float(np.arccos(cosv))\n",
        "\n",
        "def extract_pose_vector(frame, min_mean_vis=0.35):\n",
        "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    res = pose.process(img_rgb)\n",
        "    if not res.pose_landmarks:\n",
        "        return None\n",
        "\n",
        "    lms = res.pose_landmarks.landmark\n",
        "\n",
        "    lh_i = mp_pose.PoseLandmark.LEFT_HIP.value\n",
        "    rh_i = mp_pose.PoseLandmark.RIGHT_HIP.value\n",
        "    ls_i = mp_pose.PoseLandmark.LEFT_SHOULDER.value\n",
        "    rs_i = mp_pose.PoseLandmark.RIGHT_SHOULDER.value\n",
        "\n",
        "    cx = 0.5 * (lms[lh_i].x + lms[rh_i].x)\n",
        "    cy = 0.5 * (lms[lh_i].y + lms[rh_i].y)\n",
        "\n",
        "    scale = np.hypot(lms[ls_i].x - lms[rs_i].x, lms[ls_i].y - lms[rs_i].y)\n",
        "    if scale < 1e-6:\n",
        "        scale = np.hypot(lms[ls_i].x - cx, lms[ls_i].y - cy)\n",
        "    if scale < 1e-6:\n",
        "        return None\n",
        "\n",
        "    pts = np.zeros((33, 2), dtype=np.float32)\n",
        "    vis = np.zeros((33,), dtype=np.float32)\n",
        "\n",
        "    for i, lm in enumerate(lms):\n",
        "        pts[i, 0] = (lm.x - cx) / scale\n",
        "        pts[i, 1] = (lm.y - cy) / scale\n",
        "        vis[i] = lm.visibility\n",
        "\n",
        "    mean_vis = float(np.mean(vis))\n",
        "    if mean_vis < float(min_mean_vis):\n",
        "        return None\n",
        "\n",
        "    vec = pts.reshape(-1).astype(np.float32)\n",
        "\n",
        "    def p(idx):\n",
        "        return pts[idx].astype(np.float32)\n",
        "\n",
        "    le = mp_pose.PoseLandmark.LEFT_ELBOW.value\n",
        "    re = mp_pose.PoseLandmark.RIGHT_ELBOW.value\n",
        "    lw = mp_pose.PoseLandmark.LEFT_WRIST.value\n",
        "    rw = mp_pose.PoseLandmark.RIGHT_WRIST.value\n",
        "    lk = mp_pose.PoseLandmark.LEFT_KNEE.value\n",
        "    rk = mp_pose.PoseLandmark.RIGHT_KNEE.value\n",
        "    la = mp_pose.PoseLandmark.LEFT_ANKLE.value\n",
        "    ra = mp_pose.PoseLandmark.RIGHT_ANKLE.value\n",
        "\n",
        "    ang = [\n",
        "        _safe_angle(p(ls_i), p(le), p(lw)),\n",
        "        _safe_angle(p(rs_i), p(re), p(rw)),\n",
        "        _safe_angle(p(lh_i), p(lk), p(la)),\n",
        "        _safe_angle(p(rh_i), p(rk), p(ra)),\n",
        "        _safe_angle(p(le), p(ls_i), p(lh_i)),\n",
        "        _safe_angle(p(re), p(rs_i), p(rh_i)),\n",
        "        _safe_angle(p(ls_i), p(lh_i), p(lk)),\n",
        "        _safe_angle(p(rs_i), p(rh_i), p(rk)),\n",
        "    ]\n",
        "\n",
        "    out = np.concatenate([vec, np.array(ang, dtype=np.float32), np.array([mean_vis], dtype=np.float32)])\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "zQWyIbkOWVXF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1766769714.407055 11870786 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "W0000 00:00:1766769714.435238 11870790 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Содержимое DATASET_PATH:\n",
            "\u001b[34m1\u001b[m\u001b[m         \u001b[34m3\u001b[m\u001b[m         \u001b[34m5\u001b[m\u001b[m         \u001b[34m7\u001b[m\u001b[m         model.pkl\n",
            "\u001b[34m2\u001b[m\u001b[m         \u001b[34m4\u001b[m\u001b[m         \u001b[34m6\u001b[m\u001b[m         \u001b[34m8\u001b[m\u001b[m\n"
          ]
        }
      ],
      "source": [
        "print(\"Содержимое DATASET_PATH:\")\n",
        "!ls \"$DATASET_PATH\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Создаем трансформер\n",
        "augmentations = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),      # Отражаем слева направо\n",
        "    transforms.RandomRotation(degrees=15),       # Крутим на +- 15 градусов\n",
        "    transforms.ColorJitter(brightness=0.2),      # Меняем яркость\n",
        "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.7, 1.0)) # ГЛАВНОЕ: зум и обрезка\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "m1W19UGgW4Fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Класс 1\n",
            "    Видео: 1_1.mov\n",
            "    Видео: 1_2.mov\n",
            "    Видео: 1_3.mov\n",
            "    Видео: 1_4.MOV\n",
            "    Видео: 1_5.mp4\n",
            "→ Класс 2\n",
            "    Видео: 2_1.mov\n",
            "    Видео: 2_2.mov\n",
            "    Видео: 2_3.mov\n",
            "    Видео: 2_4.MOV\n",
            "    Видео: 2_5.mp4\n",
            "→ Класс 3\n",
            "    Видео: 3_1.mov\n",
            "    Видео: 3_2.mov\n",
            "    Видео: 3_3.mov\n",
            "    Видео: 3_4.MOV\n",
            "    Видео: 3_5.mp4\n",
            "→ Класс 4\n",
            "    Видео: 4_1.mov\n",
            "    Видео: 4_2.mov\n",
            "    Видео: 4_3.mov\n",
            "    Видео: 4_4.MOV\n",
            "    Видео: 4_5.mp4\n",
            "→ Класс 5\n",
            "    Видео: 5_1.mov\n",
            "    Видео: 5_2.mov\n",
            "    Видео: 5_3.mov\n",
            "    Видео: 5_4.MOV\n",
            "    Видео: 5_5.mp4\n",
            "→ Класс 6\n",
            "    Видео: 6_1.mov\n",
            "    Видео: 6_2.mov\n",
            "    Видео: 6_3.mov\n",
            "    Видео: 6_4.MOV\n",
            "    Видео: 6_5.mp4\n",
            "→ Класс 7\n",
            "    Видео: 7_1.mov\n",
            "    Видео: 7_2.mov\n",
            "    Видео: 7_3.mov\n",
            "    Видео: 7_4.MOV\n",
            "    Видео: 7_5.mp4\n",
            "→ Класс 8\n",
            "    Видео: 8_1.mov\n",
            "    Видео: 8_2.mov\n",
            "    Видео: 8_3.mov\n",
            "    Видео: 8_4.MOV\n",
            "    Видео: 8_5.mp4\n",
            "Всего поз: 5008\n",
            "Классы: ['1' '2' '3' '4' '5' '6' '7' '8']\n"
          ]
        }
      ],
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "video_ext = (\".mp4\", \".avi\", \".mov\", \".mkv\")\n",
        "\n",
        "for class_name in sorted(os.listdir(DATASET_PATH)):\n",
        "    class_path = os.path.join(DATASET_PATH, class_name)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    print(f\"→ Класс {class_name}\")\n",
        "\n",
        "    for fname in sorted(os.listdir(class_path)):\n",
        "        if not fname.lower().endswith(video_ext):\n",
        "            continue\n",
        "\n",
        "        video_path = os.path.join(class_path, fname)\n",
        "        print(f\"    Видео: {fname}\")\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frame_id = 0\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # 1. ТЕПЕРЬ БЕРЕМ КАЖДЫЙ 2-й КАДР (в 5 раз больше данных, чем было)\n",
        "            if frame_id % 2 == 0:\n",
        "                \n",
        "                # --- БЛОК АУГМЕНТАЦИИ ---\n",
        "                # Создаем копию кадра, чтобы не портить оригинал для следующих шагов\n",
        "                aug_frame = frame.copy()\n",
        "\n",
        "                # А. Рандомное отражение (слева-направо)\n",
        "                # Это самое важное, чтобы модель не привыкала, что рука в одном углу\n",
        "                if random.random() > 0.5:\n",
        "                    aug_frame = cv2.flip(aug_frame, 1)\n",
        "\n",
        "                # Б. Рандомный поворот (от -15 до 15 градусов)\n",
        "                angle = random.uniform(-15, 15)\n",
        "                h, w = aug_frame.shape[:2]\n",
        "                M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)\n",
        "                aug_frame = cv2.warpAffine(aug_frame, M, (w, h))\n",
        "\n",
        "                # В. Рандомное изменение яркости (чтобы не привязываться к свету)\n",
        "                brightness = random.uniform(0.7, 1.3)\n",
        "                aug_frame = cv2.convertScaleAbs(aug_frame, alpha=brightness, beta=0)\n",
        "                \n",
        "                # --- ИЗВЛЕЧЕНИЕ ВЕКТОРА ---\n",
        "                # Передаем уже измененный кадр\n",
        "                vec = extract_pose_vector(aug_frame)\n",
        "                \n",
        "                if vec is not None:\n",
        "                    X.append(vec)\n",
        "                    y.append(class_name)\n",
        "\n",
        "            frame_id += 1\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Всего поз:\", len(X))\n",
        "print(\"Классы:\", np.unique(y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "sAWvJ3A4ZjfZ"
      },
      "outputs": [],
      "source": [
        "if len(np.unique(y)) < 2:\n",
        "    raise ValueError(f\"Нашли только один класс: {np.unique(y)}. Проверь структуру папок и данные.\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# уменьшаем размерность, чтобы SVM жил полегче\n",
        "pca = PCA(n_components=min(40, X_train_scaled.shape[1]))\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "VLSoC9aulNDY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Отчёт по качеству:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.64      0.79      0.71       170\n",
            "           2       0.59      0.86      0.70       101\n",
            "           3       0.83      0.85      0.84       152\n",
            "           4       0.98      1.00      0.99        62\n",
            "           5       0.90      0.75      0.82       122\n",
            "           6       0.83      0.62      0.71       148\n",
            "           7       0.86      0.85      0.85       169\n",
            "           8       0.93      0.54      0.68        78\n",
            "\n",
            "    accuracy                           0.78      1002\n",
            "   macro avg       0.82      0.78      0.79      1002\n",
            "weighted avg       0.80      0.78      0.78      1002\n",
            "\n",
            "Матрица ошибок:\n",
            "[[134  16  12   0   1   6   0   1]\n",
            " [  8  87   0   0   0   6   0   0]\n",
            " [  6   6 129   0   1   0   9   1]\n",
            " [  0   0   0  62   0   0   0   0]\n",
            " [  5   3   3   0  92   5  14   0]\n",
            " [ 40   8   0   0   7  92   0   1]\n",
            " [  3   9  11   0   1   1 144   0]\n",
            " [ 13  19   1   1   0   1   1  42]]\n"
          ]
        }
      ],
      "source": [
        "clf = SVC(kernel=\"rbf\", probability=True)\n",
        "clf.fit(X_train_pca, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test_pca)\n",
        "print(\"Отчёт по качеству:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Матрица ошибок:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Ld7v7uWCtghq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Модель сохранена в: ./data/model.pkl\n"
          ]
        }
      ],
      "source": [
        "model = {\n",
        "    \"clf\": clf,\n",
        "    \"scaler\": scaler,\n",
        "    \"pca\": pca,\n",
        "    \"classes\": sorted(list(np.unique(y)))\n",
        "}\n",
        "\n",
        "model_path = os.path.join(DATASET_PATH, \"model.pkl\")\n",
        "with open(model_path, \"wb\") as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "print(\"Модель сохранена в:\", model_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "3.12.1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
