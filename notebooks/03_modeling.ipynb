{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXszINDMVmcQ"
   },
   "source": [
    "## **0. Environment Setup**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6_x3uBA7USkW"
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oeWd1TEelfEM"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1766796447.170363 12430209 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M1 Pro\n",
      "I0000 00:00:1766796447.177854 12430209 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M1 Pro\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import random\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from src.preprocessing import extract_pose_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zQWyIbkOWVXF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1766796447.194686 12433054 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1766796447.233668 12433054 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1766796447.277340 12433043 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1766796447.294571 12433048 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET_PATH content:\n",
      "\u001b[34m1\u001b[m\u001b[m         \u001b[34m3\u001b[m\u001b[m         \u001b[34m5\u001b[m\u001b[m         \u001b[34m7\u001b[m\u001b[m         README.md\n",
      "\u001b[34m2\u001b[m\u001b[m         \u001b[34m4\u001b[m\u001b[m         \u001b[34m6\u001b[m\u001b[m         \u001b[34m8\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET_PATH content:\")\n",
    "!ls \"$DATASET_PATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "m1W19UGgW4Fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1_1.mov\n",
      "1_2.mov\n",
      "1_3.mov\n",
      "1_4.MOV\n",
      "1_5.mp4\n",
      "2\n",
      "2_1.mov\n",
      "2_2.mov\n",
      "2_3.mov\n",
      "2_4.MOV\n",
      "2_5.mp4\n",
      "3\n",
      "3_1.mov\n",
      "3_2.mov\n",
      "3_3.mov\n",
      "3_4.MOV\n",
      "3_5.mp4\n",
      "4\n",
      "4_1.mov\n",
      "4_2.mov\n",
      "4_3.mov\n",
      "4_4.MOV\n",
      "4_5.mp4\n",
      "5\n",
      "5_1.mov\n",
      "5_2.mov\n",
      "5_3.mov\n",
      "5_4.MOV\n",
      "5_5.mp4\n",
      "6\n",
      "6_1.mov\n",
      "6_2.mov\n",
      "6_3.mov\n",
      "6_4.MOV\n",
      "6_5.mp4\n",
      "7\n",
      "7_1.mov\n",
      "7_2.mov\n",
      "7_3.mov\n",
      "7_4.mov\n",
      "7_5.mp4\n",
      "8\n",
      "8_1.mov\n",
      "8_2.mov\n",
      "8_3.mov\n",
      "8_4.mov\n",
      "8_5.mov\n",
      "Total poses: 4255\n",
      "Classes: ['1' '2' '3' '4' '5' '6' '7' '8']\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "video_ext = (\".mp4\", \".avi\", \".mov\", \".mkv\")\n",
    "\n",
    "for class_name in sorted(os.listdir(DATASET_PATH)):\n",
    "    class_path = os.path.join(DATASET_PATH, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    print(class_name)\n",
    "\n",
    "    for fname in sorted(os.listdir(class_path)):\n",
    "        if not fname.lower().endswith(video_ext):\n",
    "            continue\n",
    "\n",
    "        video_path = os.path.join(class_path, fname)\n",
    "        print(fname)\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_id = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_id % 2 == 0:\n",
    "                \n",
    "                # Copy frame for augmentation\n",
    "                aug_frame = frame.copy()\n",
    "\n",
    "\n",
    "                # Prevents model from bias to one side\n",
    "                if random.random() > 0.5:\n",
    "                    aug_frame = cv2.flip(aug_frame, 1)\n",
    "\n",
    "\n",
    "                angle = random.uniform(-15, 15)\n",
    "                h, w = aug_frame.shape[:2]\n",
    "                M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)\n",
    "                aug_frame = cv2.warpAffine(aug_frame, M, (w, h))\n",
    "\n",
    "\n",
    "                brightness = random.uniform(0.7, 1.3)\n",
    "                aug_frame = cv2.convertScaleAbs(aug_frame, alpha=brightness, beta=0)\n",
    "                \n",
    "                # Process augmented frame\n",
    "                vec = extract_pose_vector(aug_frame)\n",
    "                \n",
    "                if vec is not None:\n",
    "                    X.append(vec)\n",
    "                    y.append(class_name)\n",
    "\n",
    "            frame_id += 1\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Total poses:\", len(X))\n",
    "print(\"Classes:\", np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAWvJ3A4ZjfZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA: 126 -> 26 components (98% variance)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=0.98)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "print(f\"PCA: {X_train_scaled.shape[1]} -> {X_train_pca.shape[1]} components\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VLSoC9aulNDY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.95      0.95       146\n",
      "           2       0.98      0.96      0.97        90\n",
      "           3       0.96      0.97      0.97       129\n",
      "           4       0.76      1.00      0.86        59\n",
      "           5       0.97      0.95      0.96       117\n",
      "           6       0.96      0.95      0.96       137\n",
      "           7       0.98      0.96      0.97       134\n",
      "           8       0.96      0.68      0.80        38\n",
      "\n",
      "    accuracy                           0.95       850\n",
      "   macro avg       0.94      0.93      0.93       850\n",
      "weighted avg       0.95      0.95      0.95       850\n",
      "\n",
      "Confusion matrix:\n",
      "[[139   1   1   1   0   4   0   0]\n",
      " [  0  86   0   4   0   0   0   0]\n",
      " [  0   0 125   0   3   0   1   0]\n",
      " [  0   0   0  59   0   0   0   0]\n",
      " [  1   0   3   1 111   0   1   0]\n",
      " [  4   1   0   1   0 130   1   0]\n",
      " [  2   0   1   0   0   1 129   1]\n",
      " [  0   0   0  12   0   0   0  26]]\n"
     ]
    }
   ],
   "source": [
    "# we've had parameter-picking here but after finding a good one we've settled down.\n",
    "clf = SVC(C=200, gamma=0.05, kernel='rbf', probability=True)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print(\"Quality report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ld7v7uWCtghq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: ../models/model.pkl\n"
     ]
    }
   ],
   "source": [
    "model = {\n",
    "    \"clf\": clf,\n",
    "    \"scaler\": scaler,\n",
    "    \"pca\": pca,\n",
    "    \"classes\": sorted(list(np.unique(y)))\n",
    "}\n",
    "\n",
    "model_path = \"../models/model.pkl\"\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"Model saved at:\", model_path)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
